import streamlit as st
import os
import tempfile
from datetime import datetime
import requests
import json
import base64
from docx import Document
from docx.shared import Inches  # docx.shared.Inches ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì„í¬íŠ¸
import fitz  # PyMuPDF
import io
from PIL import Image
from openai import OpenAI
from dotenv import load_dotenv
import re

# ----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -----

def firecrawl_research(query, domains=None):
    """Firecrawl APIë¥¼ ì‚¬ìš©í•œ ì›¹ ë°ì´í„° ìˆ˜ì§‘"""
    
    # Firecrawl API í˜¸ì¶œ
    try:
        # ìµœì‹  ë¬¸ì„œì— ë§ëŠ” API ì—”ë“œí¬ì¸íŠ¸ (v1 ë²„ì „ ì§€ì •)
        url = "https://api.firecrawl.dev/v1/search"
        
        headers = {
            "Authorization": f"Bearer {firecrawl_api_key}",
            "Content-Type": "application/json"
        }
        
        # ê°œí–‰ ë¬¸ì ì œê±° ë° ì–‘ìª½ ê³µë°± ì œê±°
        query = query.strip()
        
        # API ìš”ì²­ í˜ì´ë¡œë“œ (v1 API ë¬¸ì„œ ê¸°ì¤€ ì—…ë°ì´íŠ¸)
        payload = {
            "query": query  # âœ… í˜„ì¬ Firecrawl v1ì—ì„œ í—ˆìš©ëœ ìœ ì¼í•œ key
        }
        
        # ì°¸ê³ : v1 APIì—ì„œëŠ” 'sites', 'num_results', 'lang', 'time_range' í•„ë“œê°€ ì§€ì›ë˜ì§€ ì•ŠìŒ
        # domains íŒŒë¼ë¯¸í„°ëŠ” ë¬´ì‹œë¨
        
        # API í˜¸ì¶œ ì „ ë¡œê·¸
        st.info(f"Firecrawl API í˜¸ì¶œ ì¤‘: {url}")
        st.info(f"API í‚¤: {firecrawl_api_key[:5]}...{firecrawl_api_key[-5:]}")
        st.info(f"ìš”ì²­ í˜ì´ë¡œë“œ: {payload}")
        
        response = requests.post(url, headers=headers, json=payload)
        
        if response.status_code == 200:
            result_data = response.json()
            
            # ë””ë²„ê¹…ìš© ì‘ë‹µ ì¶œë ¥
            st.write("API ì‘ë‹µ:", result_data.keys())
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = {
                "text_content": [],
                "images": [],
                "sources": []
            }
            
            # í…ìŠ¤íŠ¸ ì»¨í…ì¸  ì¶”ì¶œ (Firecrawl v1 API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ì¡°ì •)
            results = result_data.get("data", [])  # 'data' í•„ë“œ í™•ì¸
            
            if not results:
                # ë‹¤ë¥¸ ê°€ëŠ¥í•œ í•„ë“œë“¤ë„ í™•ì¸
                results = result_data.get("results", [])
                
                if not results and "organic" in result_data:
                    # v1 APIì—ì„œëŠ” 'organic' í•„ë“œ ì•„ë˜ì— ê²°ê³¼ê°€ ìˆì„ ìˆ˜ ìˆìŒ
                    results = result_data.get("organic", [])
                
            for item in results:
                # ìŠ¤ë‹ˆí« ì¶”ì¶œ
                if "snippet" in item:
                    formatted_results["text_content"].append(item["snippet"])
                    
                # ì œëª© ì¶”ì¶œ (v1 APIì—ì„œëŠ” ë‹¤ë¥¸ í•„ë“œëª…ì¼ ìˆ˜ ìˆìŒ)
                if "title" in item:
                    formatted_results["text_content"].append(f"ì œëª©: {item['title']}")
                    
                # URL ì¶”ì¶œ    
                if "link" in item:  # v1 APIì—ì„œëŠ” 'url' ëŒ€ì‹  'link'ì¼ ìˆ˜ ìˆìŒ
                    formatted_results["sources"].append(item["link"])
                elif "url" in item:
                    formatted_results["sources"].append(item["url"])
                    
                # ì´ë¯¸ì§€ ì¶”ì¶œ    
                if "image" in item:  # v1 APIì—ì„œëŠ” 'image_url' ëŒ€ì‹  'image'ì¼ ìˆ˜ ìˆìŒ
                    title = item.get("title", "ì´ë¯¸ì§€")
                    formatted_results["images"].append((item["image"], title))
                elif "image_url" in item and "title" in item:
                    formatted_results["images"].append((item["image_url"], item["title"]))
            
            # ì‘ë‹µ ë©”ì‹œì§€
            st.success(f"Firecrawl API ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ ì¡°íšŒë¨")
            
            # ì‘ë‹µì´ ë¹„ì–´ ìˆìœ¼ë©´ ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©
            if not formatted_results["text_content"]:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return get_example_data()
                
            return formatted_results
        else:
            # API ì˜¤ë¥˜ì‹œ ìƒì„¸ ì •ë³´ í‘œì‹œ ë° ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
            error_msg = f"API ì˜¤ë¥˜ (ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©): {response.status_code}, {response.text}"
            st.warning(error_msg)
            print(error_msg)
            
            # API í‚¤ ê²€ì¦ ë¬¸ì œì¸ ê²½ìš°
            if response.status_code == 401:
                st.error("API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ FIRECRAWL_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                
            return get_example_data()
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒì‹œ ìƒì„¸ ì •ë³´ í‘œì‹œ
        error_msg = f"API ì—°ê²° ì˜¤ë¥˜ (ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš©): {str(e)}"
        st.warning(error_msg)
        print(error_msg)
        return get_example_data()

def get_example_data():
    """ë°ëª¨ìš© ì˜ˆì‹œ ë°ì´í„°"""
    st.info("ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    return {
        "text_content": [
            "ìƒì„±í˜• AI ì‹œì¥ì€ 2025ë…„ê¹Œì§€ ì—°ê°„ 38% ì„±ì¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
            "ê¸°ì—…ë“¤ì€ AIë¥¼ í™œìš©í•œ ì—…ë¬´ ìë™í™”ì— íˆ¬ìë¥¼ í™•ëŒ€í•˜ê³  ìˆë‹¤.",
            "ChatGPTì™€ ê°™ì€ ëŒ€í™”í˜• AIëŠ” ê³ ê° ì„œë¹„ìŠ¤ ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì¼ìœ¼í‚¤ê³  ìˆë‹¤.",
            "Google DeepMindì˜ ìµœì‹  ì—°êµ¬ì— ë”°ë¥´ë©´ AI ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë§¤ë…„ 2ë°°ì”© í–¥ìƒë˜ê³  ìˆë‹¤."
        ],
        "images": [
            ("https://mblogthumb-phinf.pstatic.net/MjAyMzA0MThfMTA0/MDAxNjgxNzg2NDk1MzM4.Cz-AbXLhvkdrYGEQXS_D7P3y3rQooUW-pRXCIhKJEnAg.a5B2vWMe8YdBOZENDBmJ-VlE-vGnI2qJKBYx6YfhZ2Ig.PNG.esaracen/IMG_2.png", "AI ì‹œì¥ ì„±ì¥ ì˜ˆì¸¡ ê·¸ë˜í”„"),
            ("https://blog.kakaocdn.net/dn/bYoLUJ/btr8nQs0KRy/UXgAC0AWypxQJLKlkSrDDK/img.png", "ChatGPT ì¸í„°í˜ì´ìŠ¤")
        ],
        "sources": [
            "https://techcrunch.com/2023/05/15/ai-market-growth",
            "https://www.mckinsey.com/ai-adoption-survey-2023",
            "https://research.google/blog/ai-trends-2024"
        ]
    }

def extract_from_pdf(file_path):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ"""
    result = {
        "text_content": [],
        "images": []
    }
    
    try:
        pdf_document = fitz.open(file_path)
        
        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.get_text()
            if text.strip():
                result["text_content"].append(text)
            
            # ì´ë¯¸ì§€ ì¶”ì¶œ
            image_list = page.get_images(full=True)
            for img_index, img in enumerate(image_list):
                xref = img[0]
                base_image = pdf_document.extract_image(xref)
                image_bytes = base_image["image"]
                
                # ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì €ì¥
                image = Image.open(io.BytesIO(image_bytes))
                img_buffer = io.BytesIO()
                image.save(img_buffer, format="PNG")
                img_data = base64.b64encode(img_buffer.getvalue()).decode("utf-8")
                
                result["images"].append((f"data:image/png;base64,{img_data}", f"ì´ë¯¸ì§€ {page_num+1}-{img_index+1}"))
        
        pdf_document.close()
    except Exception as e:
        error_msg = f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}"
        st.error(error_msg)
        print(error_msg)
    
    return result

def extract_from_docx(file_path):
    """Word ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ"""
    result = {
        "text_content": [],
        "images": []
    }
    
    try:
        doc = Document(file_path)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for para in doc.paragraphs:
            if para.text.strip():
                result["text_content"].append(para.text)
        
        # ì´ë¯¸ì§€ ì¶”ì¶œ (ì¶”ê°€ êµ¬í˜„ í•„ìš”)
        # python-docxì—ì„œëŠ” ì´ë¯¸ì§€ ì¶”ì¶œì´ ì§ì ‘ì ìœ¼ë¡œ ì§€ì›ë˜ì§€ ì•ŠìŒ
        # í•„ìš” ì‹œ ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•´ êµ¬í˜„
        
    except Exception as e:
        error_msg = f"DOCX ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}"
        st.error(error_msg)
        print(error_msg)
    
    return result

def generate_report(user_query, collected_data, style="ê¸°ì‚¬í˜•", include_title=True, 
                   include_lead=True, include_body=True, include_sources=True, 
                   report_length=2, temperature=0.3):
    """GPTë¥¼ ì´ìš©í•œ ë³´ê³ ì„œ ìƒì„±"""
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = "ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ "
    
    if style == "ê¸°ì‚¬í˜•":
        prompt += "ê²½ì œ/ê¸°ìˆ  ê¸°ì‚¬ì²˜ëŸ¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë¬¸ì¥ì€ ê°„ê²°í•˜ê³ , ì •ë³´ ì¤‘ì‹¬ì ìœ¼ë¡œ êµ¬ì„±í•˜ë©°, ë…ìê°€ ë¹ ë¥´ê²Œ ìš”ì ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•´ì£¼ì„¸ìš”."
    else:
        prompt += f"ë‹¤ìŒ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”: {style}"
    
    # í¬í•¨í•  í•­ëª© ì§€ì •
    report_sections = []
    if include_title:
        report_sections.append("ì œëª© (ê°•ë ¥í•œ ë©”ì‹œì§€ë¥¼ ë‹´ì€ í—¤ë“œë¼ì¸)")
    if include_lead:
        report_sections.append("ë¦¬ë“œ ë¬¸ë‹¨ (í•µì‹¬ ìš”ì•½ ë˜ëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸ì¥)")
    if include_body:
        report_sections.append("ì£¼ìš” ë³¸ë¬¸ (ë‹¨ë½ìœ¼ë¡œ êµ¬ë¶„ëœ ìƒì„¸ ë‚´ìš©)")
    if include_sources:
        report_sections.append("ì°¸ê³  ë§í¬ ëª©ë¡")
    
    prompt += f"\n\ní¬í•¨í•  í•­ëª©: {', '.join(report_sections)}"
    
    # ë¶„ëŸ‰ ì„¤ì •
    length_map = {
        1: "ë§¤ìš° ê°„ê²°í•˜ê²Œ (300ë‹¨ì–´ ì´ë‚´)",
        2: "ê°„ê²°í•˜ê²Œ (500ë‹¨ì–´ ì´ë‚´)",
        3: "ë³´í†µ ë¶„ëŸ‰ (800ë‹¨ì–´ ì´ë‚´)",
        4: "ìƒì„¸í•˜ê²Œ (1200ë‹¨ì–´ ì´ë‚´)",
        5: "ë§¤ìš° ìƒì„¸í•˜ê²Œ (2000ë‹¨ì–´ ì´ë‚´)"
    }
    
    prompt += f"\n\në¶„ëŸ‰: {length_map[report_length]}"
    
    # ê²€ìƒ‰ ì§ˆì˜ ë° ìˆ˜ì§‘ ë°ì´í„° ì¶”ê°€
    prompt += f"\n\nì‚¬ìš©ì ì§ˆì˜: {user_query}\n\n"
    prompt += "ìˆ˜ì§‘ëœ ì •ë³´:\n"
    
    for i, text in enumerate(collected_data["text_content"]):
        prompt += f"{i+1}. {text}\n"
    
    if collected_data["sources"]:
        prompt += "\nì°¸ê³  ë§í¬:\n"
        for source in collected_data["sources"]:
            prompt += f"- {source}\n"
    
    # ë§í¬ ëª©ë¡ í˜•ì‹ì„ ëª…í™•íˆ ì§€ì •
    if include_sources and collected_data["sources"]:
        prompt += "\në§ˆì§€ë§‰ì— ë°˜ë“œì‹œ 'ì°¸ê³  ë§í¬:' ì œëª© ì•„ë˜ì— ìˆ˜ì§‘ëœ ì¶œì²˜ ë§í¬ë¥¼ ëª©ë¡ í˜•íƒœë¡œ í¬í•¨ì‹œì¼œì£¼ì„¸ìš”. ê° ë§í¬ëŠ” ìƒˆ ì¤„ì— í‘œì‹œí•˜ê³  í•˜ì´í¼ë§í¬ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
    
    # OpenAI API í˜¸ì¶œ (1.0.0 ì´ìƒ ë²„ì „ ë°©ì‹)
    try:
        client = OpenAI(api_key=openai_api_key)
        
        response = client.chat.completions.create(
            model="gpt-4",  # ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìì´ì ë¦¬ì„œì¹˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=3000
        )
        return response.choices[0].message.content
    except Exception as e:
        error_msg = f"GPT API ì˜¤ë¥˜: {str(e)}"
        st.error(error_msg)
        print(error_msg)
        return f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def format_report_with_links(report_content, sources):
    """ë³´ê³ ì„œ ë‚´ìš©ì— ì°¸ê³  ë§í¬ê°€ ì—†ëŠ” ê²½ìš° ì¶”ê°€"""
    if 'ì°¸ê³  ë§í¬:' not in report_content and sources:
        report_content += "\n\n## ì°¸ê³  ë§í¬:\n"
        for source in sources:
            report_content += f"- [{source}]({source})\n"
    
    return report_content

def create_docx_report(report_content, images=None):
    """DOCX í˜•ì‹ ë³´ê³ ì„œ ìƒì„±"""
    doc = Document()
    
    # ë§ˆí¬ë‹¤ìš´ì„ ê¸°ë³¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì²˜ë¦¬)
    lines = report_content.split('\n')
    current_paragraph = None
    
    for line in lines:
        if line.startswith('# '):
            # í° ì œëª©
            doc.add_heading(line[2:], level=0)
        elif line.startswith('## '):
            # ì¤‘ê°„ ì œëª©
            doc.add_heading(line[3:], level=1)
        elif line.startswith('### '):
            # ì‘ì€ ì œëª©
            doc.add_heading(line[4:], level=2)
        elif line.startswith('- '):
            # ëª©ë¡
            doc.add_paragraph(line[2:], style='ListBullet')
        elif line.strip() == '':
            # ë¹ˆ ì¤„
            if current_paragraph:
                current_paragraph = None
        else:
            # ì¼ë°˜ ë¬¸ë‹¨
            if not current_paragraph:
                current_paragraph = doc.add_paragraph()
            current_paragraph.add_run(line)
    
    # ì´ë¯¸ì§€ ì¶”ê°€ (ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°)
    if images:
        doc.add_heading('ê´€ë ¨ ì´ë¯¸ì§€', level=1)
        for img_url, caption in images:
            try:
                if img_url.startswith('data:image'):
                    # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
                    img_data = img_url.split(',')[1]
                    binary_img = base64.b64decode(img_data)
                    img_stream = io.BytesIO(binary_img)
                    doc.add_picture(img_stream, width=Inches(5))  # docx.shared.Inches â†’ Inchesë¡œ ìˆ˜ì •
                else:
                    # URL ì´ë¯¸ì§€ (ì‹¤ì œë¡œëŠ” ë‹¤ìš´ë¡œë“œ í•„ìš”)
                    response = requests.get(img_url)
                    img_stream = io.BytesIO(response.content)
                    doc.add_picture(img_stream, width=Inches(5))  # docx.shared.Inches â†’ Inchesë¡œ ìˆ˜ì •
                
                # ìº¡ì…˜ ì¶”ê°€ (ìŠ¤íƒ€ì¼ ì´ë¦„ ì‚¬ìš©)
                doc.add_paragraph(caption, style='Caption')
            except Exception as e:
                error_msg = f"ì´ë¯¸ì§€ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}"
                print(error_msg)
    
    # ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë¦¼ì— ì €ì¥
    docx_stream = io.BytesIO()
    doc.save(docx_stream)
    docx_stream.seek(0)
    
    return docx_stream.getvalue()

def create_pdf_report(report_content, images=None):
    """PDF í˜•ì‹ ë³´ê³ ì„œ ìƒì„± (ê°„ë‹¨í•œ êµ¬í˜„)"""
    # ì‹¤ì œ êµ¬í˜„ì€ ReportLab ë˜ëŠ” WeasyPrint ì‚¬ìš© í•„ìš”
    # ì§€ê¸ˆì€ ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
    pdf_data = io.BytesIO()
    pdf_data.write(b"PDF example data")
    pdf_data.seek(0)
    return pdf_data.getvalue()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
openai_api_key = os.getenv("OPENAI_API_KEY")
firecrawl_api_key = os.getenv("FIRECRAWL_API_KEY")

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ì¸µ ì›¹ ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ìƒì„±ê¸°",
    page_icon="ğŸ”",
    layout="wide",
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "generated_report" not in st.session_state:
    st.session_state.generated_report = None
if "report_images" not in st.session_state:
    st.session_state.report_images = []
if "report_sources" not in st.session_state:
    st.session_state.report_sources = []
if "progress" not in st.session_state:
    st.session_state.progress = 0

# ì•± ì œëª© ë° ì„¤ëª…
st.title("ğŸ” ì‹¬ì¸µ ì›¹ ë¦¬ì„œì¹˜ ìë™ ë³´ê³ ì„œ ìƒì„±ê¸°")
st.markdown("ì›¹ ë°ì´í„° ë˜ëŠ” ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ì‚¬í˜• ë³´ê³ ì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    
    # ë¬¸ì²´ ì„ íƒ
    st.subheader("ë¬¸ì²´ ì„ íƒ")
    style_option = st.radio(
        "ë³´ê³ ì„œ ìŠ¤íƒ€ì¼:",
        ["ê¸°ì‚¬í˜• (ê¸°ë³¸)", "ì§ì ‘ ì…ë ¥"],
        index=0
    )
    
    custom_style = ""
    if style_option == "ì§ì ‘ ì…ë ¥":
        custom_style = st.text_area(
            "ìŠ¤íƒ€ì¼ ì§€ì •ì„ ìœ„í•œ ì˜ˆì‹œ í…ìŠ¤íŠ¸ ë˜ëŠ” ì§€ì‹œì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”:",
            height=100
        )
    
    # ë³´ê³ ì„œ í•­ëª© ì„ íƒ
    st.subheader("ë³´ê³ ì„œ í•­ëª©")
    include_title = st.checkbox("ì œëª©", value=True)
    include_lead = st.checkbox("ë¦¬ë“œ ë¬¸ë‹¨", value=True)
    include_body = st.checkbox("ì£¼ìš” ë³¸ë¬¸", value=True)
    include_images = st.checkbox("ì´ë¯¸ì§€ í¬í•¨", value=True)
    include_sources = st.checkbox("ì°¸ê³  ë§í¬", value=True)
    
    # ë¶„ëŸ‰ ì„¤ì •
    st.subheader("ë¶„ëŸ‰ ì„¤ì •")
    report_length = st.slider("ë³´ê³ ì„œ ê¸¸ì´", min_value=1, max_value=5, value=2, 
                              help="1: ë§¤ìš° ì§§ê²Œ, 5: ë§¤ìš° ìì„¸í•˜ê²Œ")
    
    # ì¶”ê°€ ì˜µì…˜
    st.subheader("ê³ ê¸‰ ì„¤ì •")
    temperature = st.slider("ì°½ì˜ì„± ìˆ˜ì¤€", min_value=0.0, max_value=1.0, value=0.3, step=0.1,
                            help="ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ê²°ê³¼")

# íƒ­ ì„¤ì •
tab1, tab2 = st.tabs(["ë¦¬ì„œì¹˜ ì…ë ¥", "ê²°ê³¼ ë³´ê³ ì„œ"])

# ë¦¬ì„œì¹˜ ì…ë ¥ íƒ­
with tab1:
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.subheader("ì§ˆë¬¸ ë˜ëŠ” ì£¼ì œ")
        user_query = st.text_area("ì—°êµ¬í•˜ê³  ì‹¶ì€ ì§ˆë¬¸ì´ë‚˜ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=100)
        
        st.subheader("ì›¹ ë°ì´í„° ì„¤ì • (Firecrawl)")
        reference_domains = st.text_input(
            "ì°¸ì¡°í•  ë„ë©”ì¸ (ì‰¼í‘œë¡œ êµ¬ë¶„, ë¹ˆì¹¸ì´ë©´ ëª¨ë“  ì‚¬ì´íŠ¸ ê²€ìƒ‰)",
            placeholder="ì˜ˆ: techcrunch.com, korea.kr, naver.com"
        )
    
    with col2:
        st.subheader("ë¬¸ì„œ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)")
        uploaded_file = st.file_uploader("PDF ë˜ëŠ” Word ë¬¸ì„œ ì—…ë¡œë“œ", type=["pdf", "docx"])
        
        if uploaded_file:
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
    
    # ì‹¤í–‰ ë²„íŠ¼
    if st.button("ë³´ê³ ì„œ ìƒì„±í•˜ê¸°", type="primary"):
        if not user_query and not uploaded_file:
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # 1. ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„
            status_text.text("1/3 ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            collected_data = {
                "text_content": [],
                "images": [],
                "sources": []
            }
            
            # 1-A: Firecrawl APIë¥¼ í†µí•œ ì›¹ ë°ì´í„° ìˆ˜ì§‘ (ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°)
            if user_query:
                try:
                    status_text.text("ì›¹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                    
                    # Firecrawl API í˜¸ì¶œ (ê°œí–‰ ë¬¸ì ë° ê³µë°± ì œê±°)
                    firecrawl_data = firecrawl_research(user_query.strip(), reference_domains)
                    
                    collected_data["text_content"].extend(firecrawl_data.get("text_content", []))
                    collected_data["images"].extend(firecrawl_data.get("images", []))
                    collected_data["sources"].extend(firecrawl_data.get("sources", []))
                    
                    progress_bar.progress(0.3)
                except Exception as e:
                    st.error(f"ì›¹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # 1-B: ì—…ë¡œë“œëœ ë¬¸ì„œ ì²˜ë¦¬ (íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
            if uploaded_file:
                try:
                    status_text.text("ë¬¸ì„œ ë¶„ì„ ì¤‘...")
                    
                    # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬
                    if uploaded_file.name.lower().endswith('.pdf'):
                        pdf_data = extract_from_pdf(tmp_file_path)
                        collected_data["text_content"].extend(pdf_data.get("text_content", []))
                        collected_data["images"].extend(pdf_data.get("images", []))
                    
                    elif uploaded_file.name.lower().endswith('.docx'):
                        docx_data = extract_from_docx(tmp_file_path)
                        collected_data["text_content"].extend(docx_data.get("text_content", []))
                        collected_data["images"].extend(docx_data.get("images", []))
                    
                    # íŒŒì¼ëª… ì¶œì²˜ë¡œ ì¶”ê°€
                    collected_data["sources"].append(f"ì—…ë¡œë“œ ë¬¸ì„œ: {uploaded_file.name}")
                    
                    progress_bar.progress(0.5)
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # 2. ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„
            if collected_data["text_content"]:
                try:
                    status_text.text("2/3 ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„± ì¤‘...")
                    
                    # GPTë¥¼ ì´ìš©í•œ ë³´ê³ ì„œ ìƒì„±
                    report_content = generate_report(
                        user_query=user_query,
                        collected_data=collected_data,
                        style=custom_style if style_option == "ì§ì ‘ ì…ë ¥" else "ê¸°ì‚¬í˜•",
                        include_title=include_title,
                        include_lead=include_lead,
                        include_body=include_body,
                        include_sources=include_sources,
                        report_length=report_length,
                        temperature=temperature
                    )
                    
                    # ë§í¬ ëª©ë¡ í˜•ì‹ í™•ì¸ ë° ì¶”ê°€
                    report_content = format_report_with_links(report_content, collected_data["sources"])
                    
                    # ì„¸ì…˜ ìƒíƒœì— ë³´ê³ ì„œì™€ ì†ŒìŠ¤ ì €ì¥
                    st.session_state.generated_report = report_content
                    st.session_state.report_sources = collected_data["sources"]
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬ (include_imagesê°€ Trueì¸ ê²½ìš°)
                    if include_images and collected_data["images"]:
                        st.session_state.report_images = collected_data["images"][:3]  # ìµœëŒ€ 3ê°œë§Œ ì‚¬ìš©
                    
                    progress_bar.progress(0.8)
                except Exception as e:
                    st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # 3. ê²°ê³¼ ì™„ë£Œ
            status_text.text("3/3 ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬ ì¤‘...")
            progress_bar.progress(1.0)
            status_text.text("ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ! 'ê²°ê³¼ ë³´ê³ ì„œ' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            # ê²°ê³¼ íƒ­ìœ¼ë¡œ ìë™ ì „í™˜
            st.query_params.active_tab = "result"

# ê²°ê³¼ ë³´ê³ ì„œ íƒ­
with tab2:
    if st.session_state.generated_report:
        st.markdown("## ìƒì„±ëœ ë³´ê³ ì„œ")
        
        # ë³´ê³ ì„œ ë‚´ìš© í‘œì‹œ
        st.markdown(st.session_state.generated_report, unsafe_allow_html=True)
        
        # ì´ë¯¸ì§€ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
        if st.session_state.report_images and len(st.session_state.report_images) > 0:
            st.subheader("ê´€ë ¨ ì´ë¯¸ì§€")
            image_cols = st.columns(min(3, len(st.session_state.report_images)))
            
            for i, (img_url, caption) in enumerate(st.session_state.report_images):
                if i < len(image_cols):
                    with image_cols[i]:
                        try:
                            # ì´ë¯¸ì§€ URL ë””ë²„ê¹…
                            st.write(f"ì´ë¯¸ì§€ ë¡œë“œ ì¤‘: {img_url[:50]}...")
                            st.image(img_url, caption=caption, use_column_width=True)
                        except Exception as e:
                            st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        else:
            st.info("ê´€ë ¨ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì°¸ê³  ë§í¬ í‘œì‹œ
        if st.session_state.report_sources and len(st.session_state.report_sources) > 0:
            st.subheader("ì°¸ê³  ë§í¬ ëª©ë¡")
            for source in st.session_state.report_sources:
                st.markdown(f"- [{source}]({source})")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        col1, col2 = st.columns(2)
        
        with col1:
            # DOCX í˜•ì‹ ë‹¤ìš´ë¡œë“œ
            docx_file = create_docx_report(
                st.session_state.generated_report, 
                st.session_state.report_images
            )
            
            st.download_button(
                label="DOCX í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=docx_file,
                file_name=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        
        with col2:
            # PDF í˜•ì‹ ë‹¤ìš´ë¡œë“œ (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)
            st.download_button(
                label="PDF í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                data=create_pdf_report(st.session_state.generated_report, st.session_state.report_images),
                file_name=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
    else:
        st.info("ë³´ê³ ì„œê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ë¦¬ì„œì¹˜ ì…ë ¥' íƒ­ì—ì„œ ë³´ê³ ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.") 